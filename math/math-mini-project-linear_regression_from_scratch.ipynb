{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6f09811-5164-4dff-9720-f63ed6135230",
   "metadata": {},
   "source": [
    "### Linear Regression from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31336a71-e10a-43a3-89cd-0439c7bf3312",
   "metadata": {},
   "source": [
    "#### Linear Algebra\n",
    "##### Mathematical Model y^=X.theta\n",
    "- X: Feature Matrix\n",
    "- theta: parameters(weights and bias)\n",
    "- y^: Predicted values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a108658-bbea-4810-bf6e-de289c45d327",
   "metadata": {},
   "source": [
    "#### Calculus\n",
    "- Optimization of theta involves minimizing the loss function\n",
    "- Loss func: J(theta) = 1/(2m) * sum_from_1_to_m((y^_i - y_i)**2)\n",
    "- Gradient of J(theta) = 1/m(X.T(X.theta - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff015d32-1884-47d8-9169-9aa3af434403",
   "metadata": {},
   "source": [
    "#### Statistics\n",
    "- Metrics like Mean Squared Error (MSE) and R^2 are used to evaluate model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd00824-91c6-4c12-802b-45b3c76a174e",
   "metadata": {},
   "source": [
    "#### Using Gradient Descent for Parameter Optimization\n",
    "- Iteratively update theta using theta:= theta - alpha.gradientJ where alpha is learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0123fc3-9bc9-4ede-bcd0-3079078ea0a8",
   "metadata": {},
   "source": [
    "#### Evaluating the Model Statistical Metrics\n",
    "- Mean Squared Error: MSE = 1/(m) * sum_from_1_to_m((y^_i - y_i)**2)= 2 * J(theta) (Measures the average squared error)\n",
    "- R-squared (R^2) = 1 - (SS_res / SS_tot) (Measures how well the regression line explains the variance in the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98ede8e4-e993-4793-8bf0-05d9878ff4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the Mathematical Formula for Linear Regression\n",
    "import numpy as np\n",
    "\n",
    "def predict(X, theta):\n",
    "    return np.dot(X, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1b4de94-c2c3-4fce-a135-78e8a904f947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Gradient Descent to Optimize the Model parameters\n",
    "def gradient_descent(X, y, theta, learning_rate, iterations):\n",
    "    m = len(y)\n",
    "    for _ in range(iterations):\n",
    "        gradients = (1/m) * np.dot(X.T, (np.dot(X, theta) - y))\n",
    "        theta -= learning_rate * gradients\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bf99351-b487-4cfc-900a-82276123c594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Evaluation Metrics\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred)**2)\n",
    "\n",
    "def r_squared(y_true, y_pred):\n",
    "    ss_res = np.sum((y_true - y_pred)**2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true))**2)\n",
    "    return 1 - (ss_res / ss_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ed65341-a8fe-4dfe-90d1-18fd8143e68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating synthetic data\n",
    "np.random.seed(42)\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100,1)\n",
    "\n",
    "## Adding bias to feature Martrix\n",
    "X_b = np.c_[np.ones((100, 1)), X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed62c34d-bdc2-4a90-8bff-7a6019f5b00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "theta = np.random.randn(2, 1)\n",
    "learning_rate = 0.1\n",
    "iterations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "167a13c2-6423-4bca-808e-7dbbb0d30fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing gradient descent\n",
    "theta_optimized = gradient_descent(X_b, y, theta, learning_rate, iterations)\n",
    "\n",
    "# Predictions and evaluations\n",
    "y_pred = predict(X_b, theta_optimized)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "r2 = r_squared(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e5e87a-99b9-4333-9ffd-aa135ec0a0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ds-bootcamp)",
   "language": "python",
   "name": "ds-bootcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
